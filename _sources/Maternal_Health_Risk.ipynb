{"cells":[{"cell_type":"markdown","metadata":{"id":"_MKVgXsXE5Qh"},"source":["**Nama : Firlli Yuzia Rahmanu**\n","\n","**NIM : 210411100163**\n","\n","**Kelas : PSD A**\n"]},{"cell_type":"markdown","metadata":{"id":"3tPOcgpCjP98"},"source":["# **DATA MATERNAL HEALTH RISK (risiko kesehatan ibu hamil)**"]},{"cell_type":"markdown","metadata":{"id":"_fJ0qjxajG_s"},"source":["\n","\n","#**1. Deskripsi Dataset**"]},{"cell_type":"markdown","metadata":{"id":"mYM-m9QBL3M7"},"source":["\n","\n","Data diambil dari https://archive.ics.uci.edu/dataset/863/maternal+health+risk\n","\n","Deskripsi data : ancaman terhadap kesehatan ibu hamil atau calon ibu yang sedang mengandung. Hal ini sering digunakan dalam konteks kesehatan ibu hamil untuk memahami dan mengatasi risiko-risiko yang dapat memengaruhi kesehatan ibu dan perkembangan janin.\n","\n","- Jumlah data terdapat 1014\n","- Jumlah fitur ada 7\n","\n","    tipe data pada fitur :\n","    \n","    1. Age          : integer\n","    2. SystolicBP      : integer\n","    3. DiastolicBP    : integer\n","    4. BS            : float\n","    5. BodyTemp      : float\n","    6. HeartRate        : integer\n","    7. RiskLevel   : categorial\n","\n","- Tidak ada missing value, tidak ada nilai yang hilang (NaN) dalam setiap kolom. Semua kolom memiliki nilai yang lengkap dan tidak ada yang perlu diproses lebih lanjut terkait dengan data yang hilang\n","\n","- Terdapat 3 kelas di risk Level : high risk, mid risk, low risk\n","- Jumlah pada setiap kelas\n","  1. High risk : 272\n","  2. Mid risk : 336\n","  3. Low risk : 406\n","\n","- Dalam konteks data tersebut, perbedaan antara kelas terbanyak (Low risk: 406 data) dan kelas terdikit (High risk: 272 data) tidak terlalu besar, meskipun ada perbedaan.Dengan mempertimbangkan perbedaan jumlah yang relatif kecil antara kelas-kelas dalam dataset yangtersebut, dapat dikatakan bahwa data tersebut cenderung lebih seimbang atau balence.\n","\n","\n","Tujuan Klasifikasi Data :\n","- Mengklasifikasikan individu berdasarkan karakteristik dan fitur-fitur tertentu dapat membantu dalam memprediksi tingkat risiko kesehatan ibu. Ini memungkinkan penyedia layanan kesehatan untuk lebih awal mengidentifikasi calon ibu yang mungkin menghadapi risiko kesehatan tertentu selama kehamilan.\n","- Dengan mengklasifikasikan calon ibu berdasarkan risiko, perawatan dan pemantauan yang lebih intensif dapat ditargetkan pada mereka yang memiliki risiko tinggi (high). Sebaliknya, mereka dengan risiko sedang (mid) dapat menerima perawatan yang cukup, mereka dengan risiko rendah (low) dapat menerima perawatan yang lebih sederhana.\n","\n","Berikut penjelasan Fitur yang ada di dalam Dataset :\n","\n","- Age : Usia dalam tahun ketika seorang wanita sedang hamil.\n","- SystolicBP : Nilai atas Tekanan Darah dalam mmHg (milimeter raksa)\n","- DiastolicBP : Nilai bawah Tekanan Darah dalam mmHg (milimeter raksa)\n","- BS :\ttingkat glukosa darah atau gula darah dalam bentuk konsentrasi molar, mmol/L.\n","- BodyTemp : Suhu Tubuh dalam Fahrenheit\n","- HeartRate\t: Tingkat detak jantung istirahat normal dalam denyut per menit.\n","- RiskLevel : Tingkat Intensitas Risiko yang Diprediksi selama kehamilan\n","\n"]},{"cell_type":"markdown","metadata":{"id":"M1Y3dKDnjalC"},"source":["\n","#**2. Penjelasan Setiap Program itu ada di dalam Code**"]},{"cell_type":"markdown","metadata":{"id":"SB-SIgH8FVSI"},"source":["# - - -  **Connect To Google Drive** - - -\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77KQAPtxnLoa"},"outputs":[],"source":["# Connect To Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVaA-52vp69z"},"outputs":[],"source":["%cd /content/drive/MyDrive/psd/Maternal_Health_Risk"]},{"cell_type":"markdown","metadata":{"id":"YXFF2rVxHOal"},"source":["# - - -  **IMPORT LIBRARY** - - -\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwrpdcOsHQ7R"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import classification_report"]},{"cell_type":"markdown","metadata":{"id":"hCB1A3ay1U3t"},"source":["# - - -  **EKSPLORASI DATA** - - -"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ZU8ImJaGjwv"},"outputs":[],"source":["#jumlah data\n","df = pd.read_csv('Maternal_Health_Risk.csv')\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XeA8OZqqHhYJ"},"outputs":[],"source":["# mengakses tipe data dari setiap kolom dalam DataFrame.\n","df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7MS7HE6HsuD"},"outputs":[],"source":["# jumlah nilai-nilai yang hilang (NaN atau null) dalam setiap kolom DataFrame.\n","df.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"uLVd69HSIKEP"},"source":[" tidak ada nilai yang hilang (NaN) dalam setiap kolom. Semua kolom memiliki nilai yang lengkap dan tidak ada yang perlu diproses lebih lanjut terkait dengan data yang hilang."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cVKFeaVAII0o"},"outputs":[],"source":["# untuk mengelompokkan kolom-kolom berdasarkan karakteristik tertentu\n","# seperti kolom-kolom kategori (ca_val) yang mungkin berisi variabel kategori atau tipe data terbatas, dan kolom-kolom kontinu (co_val) yang mungkin berisi variabel numerik atau tipe data beragam.\n","ca_val=[]\n","co_val=[]\n","\n","for column in df.columns:\n","    if df[column].nunique() <=10:\n","        ca_val.append(column)\n","    else:\n","        co_val.append(column)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lc3w26YEIZib"},"outputs":[],"source":["#Categorical Data\n","#data yang bersifat kategorikal\n","ca_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8qdFpsKYJANQ"},"outputs":[],"source":["# berisi semua nilai yang ada dalam kolom 'BodyTemp'\n","df['BodyTemp'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGTPWc9oJKx7"},"outputs":[],"source":["# berisi semua nilai yang ada dalam kolom 'RiskLevel'\n","df['RiskLevel'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Md-5ZIW3QV9G"},"outputs":[],"source":["# data yang bersifat numerik\n","co_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CbfRiGcRQYW4"},"outputs":[],"source":["# # berisi semua nilai yang ada dalam kolom 'Age'\n","df['Age'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Txl2eQDQeSs"},"outputs":[],"source":["# berisi semua nilai yang ada dalam kolom 'SystolicBP'\n","df['SystolicBP'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZTPcKekQgaF"},"outputs":[],"source":["# berisi semua nilai yang ada dalam kolom 'DiastolicBP'\n","df['DiastolicBP'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqTrAeLeQig3"},"outputs":[],"source":["# berisi semua nilai yang ada dalam kolom 'BS'\n","df['BS'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nEV-ptQzQkMQ"},"outputs":[],"source":["# berisi semua nilai yang ada dalam kolom 'HeartRate'\n","df['HeartRate'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NHqGdKObCc_r"},"outputs":[],"source":["# Mengubah label menjadi nilai numerik\n","# Tujuan: Memfasilitasi analisis data atau pembuatan model dengan menggunakan kolom 'RiskLevel'\n","# Kolom 'RiskLevel' awalnya memiliki label kategori ('low risk', 'mid risk', 'high risk')\n","# Kode ini mengganti label tersebut menjadi nilai numerik (0, 1, 2) secara berurutan\n","# Ini memudahkan penggunaan kolom 'RiskLevel' dalam analisis atau pemodelan karena nilai numerik bisa diproses lebih mudah\n","df['RiskLevel'].replace(['low risk', 'mid risk', 'high risk'], [0, 1, 2], inplace=True)\n","\n","df  # Menampilkan DataFrame setelah transformasi kolom 'RiskLevel'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i84subBfQpv7"},"outputs":[],"source":["# Menampilkan jumlah kemunculan setiap nilai unik dalam kolom 'RiskLevel' dari DataFrame\n","# Fungsi 'value_counts()' digunakan untuk menghitung dan menampilkan jumlah kemunculan setiap nilai unik\n","# Kolom 'RiskLevel' mungkin memiliki beberapa nilai seperti 'low risk', 'mid risk', 'high risk'\n","# Kode ini membantu untuk memahami distribusi nilai dalam kolom tersebut\n","df['RiskLevel'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdM7IcXd1-_h"},"outputs":[],"source":["# Membuat plot countplot untuk kolom 'RiskLevel' dalam DataFrame 'df'\n","# plt.figure(figsize=(8, 6)) digunakan untuk menentukan ukuran plot (lebar: 8 inch, tinggi: 6 inch)\n","# sns.countplot(data=df, x='RiskLevel') membuat plot countplot menggunakan library seaborn (sns)\n","# dengan sumbu x adalah 'RiskLevel' dari DataFrame 'df'\n","# Plot ini akan menunjukkan jumlah kemunculan setiap nilai dalam kolom 'RiskLevel'\n","# plt.title('Count of Class') menambahkan judul ke plot\n","# plt.xlabel('Risk Level') dan plt.ylabel('Count') menambahkan label sumbu x dan y\n","# plt.show() menampilkan plot countplot yang telah dibuat\n","plt.figure(figsize=(8, 6))\n","sns.countplot(data=df, x='RiskLevel')\n","plt.title('Count of Class')\n","plt.xlabel('Risk Level')\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"USgIsRXT2NCs"},"source":["perbedaan antara kelas terbanyak (Low risk: 406 data) dan kelas terdikit (High risk: 272 data) tidak terlalu besar, meskipun ada perbedaan.Dengan mempertimbangkan perbedaan jumlah yang relatif kecil antara kelas-kelas dalam dataset tersebut, dapat dikatakan bahwa data tersebut cenderung lebih seimbang atau balence."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6-MJWPfRbxz"},"outputs":[],"source":["# histogram\n","# Mengimpor library matplotlib.pyplot untuk visualisasi\n","import matplotlib.pyplot as plt\n","\n","# df.hist(bins=50, figsize=(20, 15)) digunakan untuk membuat histogram untuk setiap kolom dalam DataFrame 'df'\n","# bins=50 menentukan jumlah bin (batang) pada histogram\n","# figsize=(20, 15) menentukan ukuran gambar plot histogram (lebar: 20 inch, tinggi: 15 inch)\n","df.hist(bins=50, figsize=(20, 15))\n","\n","# plt.show() digunakan untuk menampilkan plot histogram yang telah dibuat\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1iCl5_4Rl9Y"},"outputs":[],"source":["# Memisahkan dataset menjadi fitur (X) dan target (y)\n","# X adalah subset dari DataFrame df yang terdiri dari semua kolom kecuali kolom terakhir ('RiskLevel')\n","# y adalah subset dari DataFrame df yang hanya terdiri dari kolom 'RiskLevel' sebagai target\n","# X.shape digunakan untuk menampilkan dimensi dari dataset fitur (jumlah baris, jumlah kolom)\n","X = df[df.columns[:-1]]  # Memilih semua kolom kecuali kolom terakhir\n","y = df['RiskLevel']  # Memilih kolom 'RiskLevel' sebagai target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FeHTyJq_8Oo"},"outputs":[],"source":["# menampilkan lima baris pertama dari variabel X yang Memilih semua kolom kecuali kolom \"RiskLevel\"\n","X.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKsyMb7-FZia"},"outputs":[],"source":["# menampilkan lima baris pertama dari variabel y yang Memilih kolom \"RiskLevel\"\n","y.head(5)"]},{"cell_type":"markdown","metadata":{"id":"jyfvxr63B-mi"},"source":["# - - -  **SPLIT DATA** - - -\n","Funsinya untuk membagi dataset menjadi data pelatihan dan pengujian."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWQFy1N_Rp28"},"outputs":[],"source":["# Split Dataset\n","# Nilai test_size adalah 0.3, yang artinya dataset akan dibagi menjadi data pelatihan (70%) dan data pengujian (30%).\n","# Variabel X_train, X_test, y_train, y_test akan menampung data hasil pembagian.\n","# X adalah variabel independen (fitur) yang akan digunakan untuk melatih model.\n","# y adalah variabel dependen (target) yang akan diprediksi oleh model.\n","# Fungsi train_test_split dari sklearn.model_selection digunakan untuk membagi dataset menjadi data pelatihan dan pengujian.\n","# Parameter test_size=0.3 menunjukkan proporsi data pengujian yang diinginkan (30% dari dataset).\n","# Parameter random_state=42 digunakan untuk mengatur seed agar hasil pembagian data dapat direproduksi.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tPEXLr02R1DS"},"outputs":[],"source":["# Menampilkan dimensi (bentuk) dari data latih (Training) dan data uji (Testing) untuk fitur (X) dan target (y)\n","# Menggunakan fungsi shape untuk menunjukkan jumlah baris dan kolom dari setiap data\n","\n","print(f'Training Shape x:',X_train.shape)  # Menampilkan bentuk data latih untuk fitur (X)\n","print(f'Testing Shape x:',X_test.shape)    # Menampilkan bentuk data uji untuk fitur (X)\n","print('*****___________*****___________*****')  # Membuat pemisah visual antara informasi data latih dan data uji\n","\n","print(f'Training Shape y:',X.shape)       # Menampilkan bentuk data latih untuk target (y)\n","print(f'Testing Shape y:',y.shape)        # Menampilkan bentuk data uji untuk target (y)"]},{"cell_type":"markdown","metadata":{"id":"d_qKOMlKC0kI"},"source":["\n","# **3. Penjelasan Preprocessing dan Model**"]},{"cell_type":"markdown","metadata":{"id":"WT6JURurRmqW"},"source":["# - - -  **PREPROCESSING** - - -\n","\n","pada data berikut adalah :\n","- normalisasi\n"]},{"cell_type":"markdown","metadata":{"id":"X5StNPqgRjRr"},"source":["**NORMALISASI**\n","\n","- Normalisasi adalah proses transformasi data sehingga nilainya berada dalam rentang tertentu atau memiliki distribusi yang sesuai untuk analisis atau pemodelan yang lebih baik. Normalisasi dapat menggunakan berbagai metode, salah satunya adalah Normalisasi Z-Score.\n","\n","- Normalisasi Z-Score adalah salah satu teknik normalisasi yang menggunakan nilai rata-rata dan deviasi standar dari data untuk mengubah nilai-nilai tersebut ke dalam distribusi standar (distribusi normal dengan mean 0 dan standar deviasi 1).\n","\n","\n","*normalisasi yang digunakan disini adalah* **Z-Score**\n","\n","Rumus Normalisasi Z-Score:\n","\n","$ Z = \\frac{{X - \\mu}}{{\\sigma}} $\n","\n","- $Z$ adalah skor Z (Z-score).\n","- $X$ adalah nilai yang akan dinormalisasi.\n","- $\\mu\\$ adalah rerata (mean) dari sampel.\n","\n","- $\\sigma\\$ adalah deviasi standar (standard deviation) dari sampel."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R9BDeBhKR5Gb"},"outputs":[],"source":["# StandardScaler adalah sebuah metode untuk melakukan normalisasi data dengan skala Z-score.\n","# Normalisasi Z-score mengubah data sehingga memiliki rata-rata nol dan standar deviasi satu.\n","from sklearn.preprocessing import StandardScaler\n","from pickle import dump\n","\n","# Membuat objek StandardScaler\n","ss = StandardScaler()\n","\n","# Melatih (fit) StandardScaler pada data X_train\n","ss.fit(X_train)\n","\n","# Mengubah (transform) data X_train sesuai dengan skala yang telah dipelajari oleh StandardScaler\n","X_train_scaled = ss.transform(X_train)\n","\n","# Langkah yang sama dengan pendekatan yang lebih singkat:\n","# ss_X_train = ss.fit_transform(X_train)\n","# ss_X_test = ss.fit_transform(X_test)\n","\n","# Mengaplikasikan transformasi yang sama ke data test (X_test) dengan skala yang sama dari X_train\n","# Penting untuk menggunakan skala yang sama untuk data train dan test untuk memastikan konsistensi dalam analisis\n","ss_X_train = ss.transform(X_train)\n","ss_X_test = ss.transform(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xR2IGg90PWqo"},"outputs":[],"source":["from google.colab import files\n","\n","# Membuat DataFrame baru (df_normalized) dari data yang telah dinormalisasi (ss_X_train) dengan nama kolom yang sesuai dengan X_train.columns\n","df_normalized = pd.DataFrame(data=ss_X_train, columns=X_train.columns)  # Ganti X_train.columns sesuai dengan kolom yang sesuai\n","\n","# Menyimpan DataFrame ke dalam file CSV dengan nama 'hasil_sudah_normalisasi.csv' tanpa menyertakan indeks\n","df_normalized.to_csv('hasil_sudah_normalisasi_maternal.csv', index=False)\n","\n","# Mengunduh file CSV ('hasil_sudah_normalisasi.csv') yang telah disimpan\n","files.download('hasil_sudah_normalisasi_maternal.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4UtVDk-Pf3m"},"outputs":[],"source":["# Simpan model dengan file pickle\n","# Mengimpor modul pickle yang memungkinkan penyimpanan objek Python ke dalam file\n","import pickle\n","\n","# Path atau lokasi file di mana model akan disimpan\n","file = '/content/drive/MyDrive/psd/Maternal_Health_Risk/normalisasi_ini.pkl'\n","\n","# Membuka file dalam mode write binary ('wb') untuk menyimpan model\n","# 'ss' adalah objek yang akan disimpan (model normalisasi atau objek lainnya)\n","# pickle.dump(ss, file) digunakan untuk menyimpan objek 'ss' ke dalam file menggunakan pickle\n","with open(file, 'wb') as file:\n","    pickle.dump(ss, file)\n"]},{"cell_type":"markdown","metadata":{"id":"0ulZMWUNEr2c"},"source":["# - - -  **MODEL** - - -"]},{"cell_type":"markdown","metadata":{"id":"zKedK4oxVSxv"},"source":["**Perbandingan Beberapa Model dengan akurasi**\n","\n","- **SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5xnI7ALR8wq"},"outputs":[],"source":["# SVM\n","# Import modul SVC (Support Vector Classifier) dari pustaka Scikit-learn\n","from sklearn.svm import SVC\n","\n","# Membuat model SVM dengan parameter tertentu\n","svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n","\n","# Melatih model menggunakan data X_train dan y_train\n","svm.fit(X_train, y_train)\n","\n","# Menampilkan akurasi pada data latih (train) dan data uji (test)\n","print(\"Train accuracy:\", svm.score(X_train, y_train))\n","print(\"Test accuracy:\", svm.score(X_test, y_test))\n","\n","# Memprediksi nilai target (y) menggunakan data uji (X_test)\n","y_pred = svm.predict(X_test)\n","\n","# Menampilkan prediksi yang dihasilkan oleh model\n","print(y_pred)\n","\n","# Menghitung dan menampilkan confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(f'Confusion Matrix:', cm)\n","\n","# Menghitung dan menampilkan akurasi dari model SVM\n","print(f'Accuracy:', accuracy_score(y_test, y_pred) * 100, '%')\n","\n","# Menampilkan precision, recall, f1-score, dan support dari model SVM\n","print(classification_report(y_test, svm.predict(X_test)))\n"]},{"cell_type":"markdown","metadata":{"id":"yubI0JUAZMDg"},"source":["- **Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5SnRz38SvDL"},"outputs":[],"source":["# Decision Tree\n","from sklearn import tree  # Mengimpor modul Decision Tree dari library scikit-learn\n","decision_tree = tree.DecisionTreeClassifier(criterion='gini')  # Membuat objek Decision Tree Classifier dengan kriteria 'gini'\n","decision_tree.fit(X_train, y_train)  # Melatih model Decision Tree menggunakan data training (X_train dan y_train)\n","\n","# Menampilkan akurasi model pada data training dan data testing\n","print(\"Train accuracy:\", decision_tree.score(X_train, y_train))  # Menampilkan akurasi model pada data training\n","print(\"Test accuracy:\", decision_tree.score(X_test, y_test))  # Menampilkan akurasi model pada data testing\n","\n","y_pred = decision_tree.predict(X_test)  # Memprediksi label dari data testing menggunakan model Decision Tree\n","print(y_pred)  # Menampilkan hasil prediksi\n","\n","# Menghitung dan menampilkan confusion matrix\n","cm = confusion_matrix(y_test, y_pred)  # Menghitung confusion matrix dari hasil prediksi dan nilai sebenarnya\n","print(f'CM:', cm)  # Menampilkan confusion matrix\n","print(f'Accuracy:', accuracy_score(y_test, y_pred) * 100, '%')  # Menampilkan akurasi dari hasil prediksi\n","\n","# Menampilkan precision, recall, f1-score, dan support\n","print(classification_report(y_test, decision_tree.predict(X_test)))  # Menampilkan laporan klasifikasi berdasarkan hasil prediksi"]},{"cell_type":"markdown","metadata":{"id":"soI-ykdEZkEI"},"source":["- **Gaussian Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIhUmAktZjU7"},"outputs":[],"source":["# Gaussian Naive Bayes (GaussianNB)\n","from sklearn.naive_bayes import GaussianNB\n","\n","# Membuat model Naive Bayes dengan tipe Gaussian\n","nb = GaussianNB()\n","\n","# Melatih model dengan data training (X_train dan y_train)\n","nb.fit(X_train , y_train)\n","\n","# Mencetak akurasi model pada data training dan data test\n","print(\"Train accuracy:\", nb.score(X_train, y_train))\n","print(\"Test accuracy:\", nb.score(X_test, y_test))\n","\n","# Melakukan prediksi menggunakan data test\n","y_pred = nb.predict(X_test)\n","\n","# Mencetak hasil prediksi\n","print(y_pred)\n","\n","# Menghitung confusion matrix antara hasil prediksi (y_pred) dan nilai sebenarnya (y_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print(f'Confusion Matrix:', cm)\n","\n","# Menghitung dan mencetak tingkat akurasi dari hasil prediksi\n","print(f'Accuracy:', accuracy_score(y_test, y_pred) * 100, '%')\n","\n","# Mencetak laporan klasifikasi yang berisi precision, recall, f1-score, dan support\n","print(classification_report(y_test, nb.predict(X_test)))"]},{"cell_type":"markdown","metadata":{"id":"EonJ3SGKaCKO"},"source":["- **LogisticRegression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8K06H4YTaCnK"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","# Membuat objek model Regresi Logistik\n","model = LogisticRegression()\n","\n","# Melatih model menggunakan data X_train dan y_train\n","model.fit(X_train, y_train)\n","\n","# Memprediksi nilai target menggunakan data X_test\n","y_pred = model.predict(X_test)\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","# Mencetak nilai Akurasi (Accuracy Score) dari prediksi model terhadap data y_test\n","print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"]},{"cell_type":"markdown","metadata":{"id":"iXbby4k_Z2vh"},"source":["- **KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZO-CZG30Z15H"},"outputs":[],"source":["# Menggunakan algoritma K-Nearest Neighbors untuk klasifikasi dengan variasi nilai k\n","from sklearn.neighbors import KNeighborsClassifier  # Import KNeighborsClassifier dari scikit-learn\n","from sklearn.metrics import accuracy_score  # Import accuracy_score untuk mengukur akurasi\n","\n","akurasi_terbaik = 0  # Inisialisasi variabel untuk menyimpan akurasi terbaik\n","k_terbaik = 0  # Inisialisasi variabel untuk menyimpan nilai k terbaik\n","\n","# Loop untuk mencoba berbagai nilai k dari 1 hingga 20\n","for k in range(1, 21):\n","    model = KNeighborsClassifier(n_neighbors=k)  # Membuat model KNN dengan nilai k tertentu\n","    model.fit(X_train, y_train)  # Melatih model dengan data latih\n","    hasil_prediksi = model.predict(X_test)  # Melakukan prediksi dengan data uji\n","\n","    akurasi = accuracy_score(y_test, hasil_prediksi)  # Menghitung akurasi prediksi\n","    print(f\"k = {k}, Skor Akurasi: {akurasi}\")  # Menampilkan skor akurasi untuk setiap nilai k\n","\n","    # Memeriksa jika akurasi terbaik diperbarui, jika ya, perbarui nilai k_terbaik dan akurasi_terbaik\n","    if akurasi > akurasi_terbaik:\n","        akurasi_terbaik = akurasi\n","        k_terbaik = k\n","\n","# Menampilkan nilai k terbaik dan skor akurasi terbaik yang telah ditemukan\n","print(f\"k Terbaik: {k_terbaik} dengan Skor Akurasi: {akurasi_terbaik}\")"]},{"cell_type":"markdown","metadata":{"id":"elUZp5gdaM3b"},"source":["- **Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Q4UlhELT6jk"},"outputs":[],"source":["# RandomForest\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Membuat model RandomForestClassifier\n","random_forest = RandomForestClassifier()\n","\n","# Melatih model menggunakan data X_train dan y_train\n","random_forest.fit(X_train, y_train)\n","\n","# Menampilkan akurasi model pada data latih (train) dan data uji (test)\n","print(\"Train accuracy:\", random_forest.score(X_train, y_train))\n","print(\"Test accuracy:\", random_forest.score(X_test, y_test))\n","\n","# Melakukan prediksi terhadap data uji (test)\n","y_pred = random_forest.predict(X_test)\n","\n","# Menampilkan hasil prediksi\n","print(y_pred)\n","\n","# Menghitung confusion matrix untuk mengevaluasi performa model\n","cm = confusion_matrix(y_test, y_pred)\n","print(f'Confusion Matrix:', cm)\n","\n","# Menghitung dan menampilkan akurasi model\n","print(f'Accuracy:', accuracy_score(y_test, y_pred) * 100, '%')\n","\n","# Menampilkan laporan klasifikasi yang berisi precision, recall, dan f1-score\n","print(classification_report(y_test, random_forest.predict(X_test)))"]},{"cell_type":"markdown","metadata":{"id":"gbHuzGlba5UB"},"source":["**MODEL TERBAIK YANG DIGUNAKAN ADALAH RANDOM FOREST**\n","\n","Model Random Forest adalah salah satu algoritma supervised learning dalam machine learning yang dapat digunakan untuk tugas klasifikasi dan regresi. Algoritma ini berada dalam kelompok ensemble learning yang menggabungkan beberapa pohon keputusan (decision trees) untuk membuat prediksi yang lebih akurat.\n","\n","Berikut adalah beberapa poin penjelasan tentang Model Random Forest:\n","\n","- Supervised Learning : model atau algoritma belajar dari data yang telah ditandai atau berlabel. Dalam supervised learning, model dilatih menggunakan dataset yang terdiri dari pasangan input dan output yang telah diberi label.\n","\n","- Ensemble Learning: Random Forest merupakan teknik ensemble learning yang menggabungkan hasil dari beberapa model (pohon keputusan) untuk membuat keputusan akhir. Hal ini membantu dalam mengatasi masalah overfitting (pemodelan yang terlalu pas dengan data latih namun tidak umum).\n","\n","- Pohon Keputusan: Setiap pohon keputusan dalam Random Forest merupakan model yang terdiri dari serangkaian keputusan berhierarki yang dibuat berdasarkan fitur-fitur dari data latih. Pohon-pohon ini bergantung satu sama lain dan melakukan prediksi secara kolektif.\n","\n","- Randomization: Keunikan dari Random Forest adalah dalam proses pembentukan pohon-pohon keputusan yang dilakukan secara acak. Proses ini melibatkan pemilihan acak dari fitur-fitur untuk setiap pohon dan pembagian acak dari sampel data untuk setiap pohon.\n","\n","- Model Random Forest memiliki kelebihan dalam menangani data yang kompleks, fitur-fitur yang tidak relevan, serta toleran terhadap overfitting. Selain itu, model ini dapat memberikan perkiraan pentingnya (importance) dari masing-masing fitur dalam prediksi.\n","\n","**Konsep Random Forest:**\n","\n","1. Bootstrap Aggregating (Bagging):\n","- Langkah pertama adalah mengambil sampel acak dari dataset dengan penggantian (bootstrap) untuk membuat beberapa dataset baru.\n","- Setiap dataset baru ini digunakan untuk melatih pohon keputusan yang berbeda.\n","2. Decision Trees (Pohon Keputusan):\n","- Setiap dataset hasil dari bagging digunakan untuk membuat pohon keputusan secara independen.\n","- Masing-masing pohon memilih fitur terbaik untuk membagi data menjadi subset yang semakin murni.\n","3. Ensemble dan Prediksi:\n","- Ketika ada data baru yang perlu diprediksi, setiap pohon memberikan hasil prediksi.\n","- Dalam kasus klasifikasi, hasil mayoritas dari semua prediksi pohon diambil sebagai prediksi akhir.\n","\n","**Rumus Random Forest Classifier:**\n","\n","$\\hat{Y} = \\frac{1}{N} \\sum_{i=1}^{N} f_i(X)$\n","\n","di mana:\n","\n","$\\hat{Y}$ adalah prediksi akhir,\n","\n","$N$ adalah jumlah pohon keputusan dalam ensemble,\n","\n","$X$ adalah prediksi yang dihasilkan oleh pohon keputusan ke-\n","i.\n","\n","\n","**Contoh Penghitungan Random Forest pada Kasus Klasifikasi:**\n","\n","Misalkan kita memiliki ensemble Random Forest dengan 3 pohon keputusan. Setiap pohon menghasilkan prediksi terhadap sebuah sampel data sebagai berikut:\n","\n","Pohon 1: Prediksi kelas A\n","\n","Pohon 2: Prediksi kelas B\n","\n","Pohon 3: Prediksi kelas A\n","\n","Dalam kasus ini, kita mengambil hasil mayoritas prediksi:\n","\n","Kelas A muncul 2 kali.\n","\n","Kelas B muncul 1 kali.\n","\n","Maka, hasil prediksi akhir dari ensemble Random Forest adalah kelas A karena memiliki jumlah prediksi terbanyak.\n"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUuDnuxlsaKW","executionInfo":{"status":"ok","timestamp":1700413976202,"user_tz":-420,"elapsed":6361,"user":{"displayName":"21-163_FIRLLI YUZIA RAHMANU","userId":"07543586146755139642"}},"outputId":"f719cef2-08a0-4544-8036-e1b76a80953a"},"outputs":[{"output_type":"stream","name":"stdout","text":["random_state = 1, Skor Akurasi: 0.8065573770491803\n","random_state = 2, Skor Akurasi: 0.7967213114754098\n","random_state = 3, Skor Akurasi: 0.8065573770491803\n","random_state = 4, Skor Akurasi: 0.8098360655737705\n","random_state = 5, Skor Akurasi: 0.8098360655737705\n","random_state = 6, Skor Akurasi: 0.7934426229508197\n","random_state = 7, Skor Akurasi: 0.8032786885245902\n","random_state = 8, Skor Akurasi: 0.8032786885245902\n","random_state = 9, Skor Akurasi: 0.7967213114754098\n","random_state = 10, Skor Akurasi: 0.8\n","random_state = 11, Skor Akurasi: 0.7967213114754098\n","random_state = 12, Skor Akurasi: 0.7967213114754098\n","random_state = 13, Skor Akurasi: 0.7901639344262295\n","random_state = 14, Skor Akurasi: 0.8032786885245902\n","random_state = 15, Skor Akurasi: 0.8\n","random_state = 16, Skor Akurasi: 0.7967213114754098\n","random_state = 17, Skor Akurasi: 0.8098360655737705\n","random_state = 18, Skor Akurasi: 0.8098360655737705\n","random_state = 19, Skor Akurasi: 0.7901639344262295\n","random_state = 20, Skor Akurasi: 0.8065573770491803\n","random_state Terbaik: 4 dengan Skor Akurasi: 0.8098360655737705\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier  # Import library untuk RandomForestClassifier\n","from sklearn.metrics import accuracy_score  # Import library untuk mengukur akurasi\n","import pickle  # Import library untuk penyimpanan model\n","\n","akurasi_terbaik_rf = 0  # Inisialisasi variabel untuk menyimpan nilai akurasi tertinggi\n","random_state_terbaik_rf = 0  # Inisialisasi variabel untuk menyimpan nilai random_state terbaik\n","model_terbaik = None  # Inisialisasi variabel untuk menyimpan model terbaik\n","\n","# Loop untuk mencari model dengan random_state terbaik dari 1 hingga 20\n","for random_state_rf in range(1, 21):\n","    # Membuat model RandomForestClassifier dengan random_state tertentu\n","    model2 = RandomForestClassifier(random_state=random_state_rf)\n","\n","    # Melatih model menggunakan data X_train dan y_train\n","    model2.fit(X_train, y_train)\n","\n","    # Melakukan prediksi menggunakan data X_test\n","    hasil_prediksi_rf = model2.predict(X_test)\n","\n","    # Mengukur akurasi dari model yang telah dilatih\n","    akurasi_rf = accuracy_score(y_test, hasil_prediksi_rf)\n","    print(f\"random_state = {random_state_rf}, Skor Akurasi: {akurasi_rf}\")\n","\n","    # Memilih model dengan akurasi tertinggi sebagai model terbaik\n","    if akurasi_rf > akurasi_terbaik_rf:\n","        akurasi_terbaik_rf = akurasi_rf\n","        random_state_terbaik_rf = random_state_rf\n","        model_terbaik = model2  # Simpan model dengan akurasi tertinggi\n","\n","# Menampilkan nilai random_state terbaik dan akurasi tertinggi yang diperoleh\n","print(f\"random_state Terbaik: {random_state_terbaik_rf} dengan Skor Akurasi: {akurasi_terbaik_rf}\")\n","\n","# Simpan model dengan akurasi tertinggi ke dalam file 'best_model.pkl'\n","with open('best_model.pkl', 'wb') as file:\n","    pickle.dump(model_terbaik, file)\n"]},{"cell_type":"markdown","metadata":{"id":"9xqs9AB6Jkn0"},"source":["Model dengan akurasi terbaik adalah Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tzfrY5ZEJMjy"},"outputs":[],"source":["# Simpan model dengan file pickle\n","import pickle\n","file = '/content/drive/MyDrive/psd/Maternal_Health_Risk/model_randomForest_ini.pkl'\n","\n","with open(file, 'wb') as file:\n","    pickle.dump(random_forest, file)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}